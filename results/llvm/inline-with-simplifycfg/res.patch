diff --git a/llvm/include/llvm/Analysis/InlineCost.h b/llvm/include/llvm/Analysis/InlineCost.h
index c5978ce54fc1..b89cc0fd4ed9 100644
--- a/llvm/include/llvm/Analysis/InlineCost.h
+++ b/llvm/include/llvm/Analysis/InlineCost.h
@@ -41,7 +41,7 @@ const int OptSizeThreshold = 50;
 const int OptMinSizeThreshold = 5;
 
 /// Use when -O3 is specified.
-const int OptAggressiveThreshold = 250;
+const int OptAggressiveThreshold = 2500;
 
 // Various magic constants used to adjust heuristics.
 int getInstrCost();
diff --git a/llvm/include/llvm/Analysis/TargetTransformInfoImpl.h b/llvm/include/llvm/Analysis/TargetTransformInfoImpl.h
index 00efa474a91b..b732a62c366a 100644
--- a/llvm/include/llvm/Analysis/TargetTransformInfoImpl.h
+++ b/llvm/include/llvm/Analysis/TargetTransformInfoImpl.h
@@ -430,7 +430,7 @@ public:
   bool isFCmpOrdCheaperThanFCmpZero(Type *Ty) const { return true; }
 
   InstructionCost getFPOpCost(Type *Ty) const {
-    return TargetTransformInfo::TCC_Basic;
+    return TargetTransformInfo::TCC_Expensive;
   }
 
   InstructionCost getIntImmCodeSizeCost(unsigned Opcode, unsigned Idx,
diff --git a/llvm/include/llvm/CodeGen/BasicTTIImpl.h b/llvm/include/llvm/CodeGen/BasicTTIImpl.h
index 5b9cc5dfeead..38c6fd7fea5d 100644
--- a/llvm/include/llvm/CodeGen/BasicTTIImpl.h
+++ b/llvm/include/llvm/CodeGen/BasicTTIImpl.h
@@ -551,10 +551,10 @@ public:
   InstructionCost getFPOpCost(Type *Ty) {
     // Check whether FADD is available, as a proxy for floating-point in
     // general.
-    const TargetLoweringBase *TLI = getTLI();
-    EVT VT = TLI->getValueType(DL, Ty);
-    if (TLI->isOperationLegalOrCustomOrPromote(ISD::FADD, VT))
-      return TargetTransformInfo::TCC_Basic;
+    // const TargetLoweringBase *TLI = getTLI();
+    // EVT VT = TLI->getValueType(DL, Ty);
+    // if (TLI->isOperationLegalOrCustomOrPromote(ISD::FADD, VT))
+    //   return TargetTransformInfo::TCC_Basic;
     return TargetTransformInfo::TCC_Expensive;
   }
 
diff --git a/llvm/include/llvm/Transforms/Utils/SimplifyCFGOptions.h b/llvm/include/llvm/Transforms/Utils/SimplifyCFGOptions.h
index 2ea9d64f03cb..f6c0df43a5cb 100644
--- a/llvm/include/llvm/Transforms/Utils/SimplifyCFGOptions.h
+++ b/llvm/include/llvm/Transforms/Utils/SimplifyCFGOptions.h
@@ -29,7 +29,7 @@ struct SimplifyCFGOptions {
   bool HoistCommonInsts = false;
   bool SinkCommonInsts = false;
   bool SimplifyCondBranch = true;
-  bool SpeculateBlocks = true;
+  bool SpeculateBlocks = false;
   bool SpeculateUnpredictables = false;
 
   AssumptionCache *AC = nullptr;
diff --git a/llvm/lib/Analysis/InlineCost.cpp b/llvm/lib/Analysis/InlineCost.cpp
index 345e5a019520..5405c696e176 100644
--- a/llvm/lib/Analysis/InlineCost.cpp
+++ b/llvm/lib/Analysis/InlineCost.cpp
@@ -54,7 +54,7 @@ using namespace llvm;
 STATISTIC(NumCallsAnalyzed, "Number of call sites analyzed");
 
 static cl::opt<int>
-    DefaultThreshold("inlinedefault-threshold", cl::Hidden, cl::init(225),
+    DefaultThreshold("inlinedefault-threshold", cl::Hidden, cl::init(2500),
                      cl::desc("Default amount of inlining to perform"));
 
 // We introduce this option since there is a minor compile-time win by avoiding
@@ -72,16 +72,16 @@ static cl::opt<bool> PrintInstructionComments(
     cl::desc("Prints comments for instruction based on inline cost analysis"));
 
 static cl::opt<int> InlineThreshold(
-    "inline-threshold", cl::Hidden, cl::init(225),
-    cl::desc("Control the amount of inlining to perform (default = 225)"));
+    "inline-threshold", cl::Hidden, cl::init(2500),
+    cl::desc("Control the amount of inlining to perform (default = 450)"));
 
 static cl::opt<int> HintThreshold(
-    "inlinehint-threshold", cl::Hidden, cl::init(325),
+    "inlinehint-threshold", cl::Hidden, cl::init(5000),
     cl::desc("Threshold for inlining functions with inline hint"));
 
 static cl::opt<int>
     ColdCallSiteThreshold("inline-cold-callsite-threshold", cl::Hidden,
-                          cl::init(45),
+                          cl::init(90),
                           cl::desc("Threshold for inlining cold callsites"));
 
 static cl::opt<bool> InlineEnableCostBenefitAnalysis(
@@ -136,15 +136,15 @@ static cl::opt<uint64_t> HotCallSiteRelFreq(
              "profile information."));
 
 static cl::opt<int>
-    InstrCost("inline-instr-cost", cl::Hidden, cl::init(5),
+    InstrCost("inline-instr-cost", cl::Hidden, cl::init(1),
               cl::desc("Cost of a single instruction when inlining"));
 
 static cl::opt<int>
-    MemAccessCost("inline-memaccess-cost", cl::Hidden, cl::init(0),
+    MemAccessCost("inline-memaccess-cost", cl::Hidden, cl::init(1),
                   cl::desc("Cost of load/store instruction when inlining"));
 
 static cl::opt<int> CallPenalty(
-    "inline-call-penalty", cl::Hidden, cl::init(25),
+    "inline-call-penalty", cl::Hidden, cl::init(5),
     cl::desc("Call penalty that is applied per callsite when inlining"));
 
 static cl::opt<size_t>
diff --git a/llvm/lib/Passes/PassBuilderPipelines.cpp b/llvm/lib/Passes/PassBuilderPipelines.cpp
index 6f36bdad780a..2de4d0fda7f9 100644
--- a/llvm/lib/Passes/PassBuilderPipelines.cpp
+++ b/llvm/lib/Passes/PassBuilderPipelines.cpp
@@ -232,7 +232,7 @@ static cl::opt<bool> EnablePGOForceFunctionAttrs(
     cl::init(false));
 
 static cl::opt<bool>
-    EnableHotColdSplit("hot-cold-split",
+    EnableHotColdSplit("hot-cold-split",                      
                        cl::desc("Enable hot-cold splitting pass"));
 
 static cl::opt<bool> EnableIROutliner("ir-outliner", cl::init(false),
@@ -577,7 +577,7 @@ PassBuilder::buildFunctionSimplificationPipeline(OptimizationLevel Level,
   }
 
   // Speculative execution if the target has divergent branches; otherwise nop.
-  FPM.addPass(SpeculativeExecutionPass(/* OnlyIfDivergentTarget =*/true));
+  //FPM.addPass(SpeculativeExecutionPass(/* OnlyIfDivergentTarget =*/true));
 
   // Optimize based on known information about branches, and cleanup afterward.
   FPM.addPass(JumpThreadingPass());
@@ -1528,8 +1528,8 @@ PassBuilder::buildModuleOptimizationPipeline(OptimizationLevel Level,
   // Split out cold code. Splitting is done late to avoid hiding context from
   // other optimizations and inadvertently regressing performance. The tradeoff
   // is that this has a higher code size cost than splitting early.
-  if (EnableHotColdSplit && !LTOPreLink)
-    MPM.addPass(HotColdSplittingPass());
+  // if (EnableHotColdSplit && !LTOPreLink)
+  //   MPM.addPass(HotColdSplittingPass());
 
   // Search the code for similar regions of code. If enough similar regions can
   // be found where extracting the regions into their own function will decrease
@@ -2017,8 +2017,8 @@ PassBuilder::buildLTODefaultPipeline(OptimizationLevel Level,
   MPM.addPass(LowerTypeTestsPass(nullptr, nullptr, true));
 
   // Enable splitting late in the FullLTO post-link pipeline.
-  if (EnableHotColdSplit)
-    MPM.addPass(HotColdSplittingPass());
+  // if (EnableHotColdSplit)
+  //   MPM.addPass(HotColdSplittingPass());
 
   // Add late LTO optimization passes.
   FunctionPassManager LateFPM;
diff --git a/llvm/lib/Target/RISCV/RISCVISelLowering.cpp b/llvm/lib/Target/RISCV/RISCVISelLowering.cpp
index badbb4259974..4a51d73f7a70 100644
--- a/llvm/lib/Target/RISCV/RISCVISelLowering.cpp
+++ b/llvm/lib/Target/RISCV/RISCVISelLowering.cpp
@@ -21580,8 +21580,9 @@ bool RISCVTargetLowering::isIntDivCheap(EVT VT, AttributeList Attr) const {
   // When aggressively optimizing for code size, we prefer to use a div
   // instruction, as it is usually smaller than the alternative sequence.
   // TODO: Add vector division?
-  bool OptSize = Attr.hasFnAttr(Attribute::MinSize);
-  return OptSize && !VT.isVector();
+  // bool OptSize = Attr.hasFnAttr(Attribute::MinSize);
+  // return OptSize && !VT.isVector();
+  return true;
 }
 
 bool RISCVTargetLowering::preferScalarizeSplat(SDNode *N) const {
diff --git a/llvm/lib/Target/RISCV/RISCVTargetMachine.cpp b/llvm/lib/Target/RISCV/RISCVTargetMachine.cpp
index 21fbf47875e6..c492ae87679f 100644
--- a/llvm/lib/Target/RISCV/RISCVTargetMachine.cpp
+++ b/llvm/lib/Target/RISCV/RISCVTargetMachine.cpp
@@ -91,7 +91,7 @@ static cl::opt<bool>
 static cl::opt<bool>
     EnableLoopDataPrefetch("riscv-enable-loop-data-prefetch", cl::Hidden,
                            cl::desc("Enable the loop data prefetch pass"),
-                           cl::init(true));
+                           cl::init(false));
 
 static cl::opt<bool> EnableMISchedLoadClustering(
     "riscv-misched-load-clustering", cl::Hidden,
@@ -420,8 +420,8 @@ void RISCVPassConfig::addIRPasses() {
   addPass(createAtomicExpandLegacyPass());
 
   if (getOptLevel() != CodeGenOptLevel::None) {
-    if (EnableLoopDataPrefetch)
-      addPass(createLoopDataPrefetchPass());
+    // if (EnableLoopDataPrefetch)
+    //   addPass(createLoopDataPrefetchPass());
 
     addPass(createRISCVGatherScatterLoweringPass());
     addPass(createInterleavedAccessPass());
diff --git a/llvm/lib/Target/RISCV/RISCVTargetTransformInfo.cpp b/llvm/lib/Target/RISCV/RISCVTargetTransformInfo.cpp
index 5a92d6bab31a..01624fe2628a 100644
--- a/llvm/lib/Target/RISCV/RISCVTargetTransformInfo.cpp
+++ b/llvm/lib/Target/RISCV/RISCVTargetTransformInfo.cpp
@@ -762,6 +762,7 @@ InstructionCost RISCVTTIImpl::getStridedMemoryOpCost(
 // for the respective intrinsics.  The costs in this table are simply
 // instruction counts with the following adjustments made:
 // * One vsetvli is considered free.
+// TODO
 static const CostTblEntry VectorIntrinsicCostTable[]{
     {Intrinsic::floor, MVT::f32, 9},
     {Intrinsic::floor, MVT::f64, 9},
@@ -1381,6 +1382,12 @@ InstructionCost RISCVTTIImpl::getMemoryOpCost(unsigned Opcode, Type *Src,
                                               TTI::TargetCostKind CostKind,
                                               TTI::OperandValueInfo OpInfo,
                                               const Instruction *I) {
+  if (!Src->isVectorTy()) {
+    unsigned align = Alignment ? Alignment->value() : Src->getScalarSizeInBits() / 8;
+    if (Opcode == Instruction::Load || Opcode == Instruction::Store) {
+      return align < 4 ? 12 : 1;
+    }
+  }
   EVT VT = TLI->getValueType(DL, Src, true);
   // Type legalization can't handle structs
   if (VT == MVT::Other)
@@ -1390,9 +1397,7 @@ InstructionCost RISCVTTIImpl::getMemoryOpCost(unsigned Opcode, Type *Src,
   InstructionCost Cost = 0;
   if (Opcode == Instruction::Store && OpInfo.isConstant())
     Cost += getStoreImmCost(Src, OpInfo, CostKind);
-  InstructionCost BaseCost =
-    BaseT::getMemoryOpCost(Opcode, Src, Alignment, AddressSpace,
-                           CostKind, OpInfo, I);
+  InstructionCost BaseCost = 1;
   // Assume memory ops cost scale with the number of vector registers
   // possible accessed by the instruction.  Note that BasicTTI already
   // handles the LT.first term for us.
@@ -1683,6 +1688,39 @@ InstructionCost RISCVTTIImpl::getArithmeticInstrCost(
   // Legalize the type.
   std::pair<InstructionCost, MVT> LT = getTypeLegalizationCost(Ty);
 
+  if (!LT.second.isVector()) {
+    switch (Opcode) {
+      // 1-cycle operations
+      case Instruction::Add:
+      case Instruction::Sub:
+      case Instruction::Mul:
+      case Instruction::Shl:
+        return 1;
+      // 2-cycle operations
+      case Instruction::And:
+      case Instruction::Or:
+      case Instruction::Xor:
+      case Instruction::UDiv:
+      case Instruction::SDiv:
+      case Instruction::URem:
+      case Instruction::SRem:
+      case Instruction::LShr:
+      case Instruction::AShr:
+        return 2;
+      // Floating point is more expensive (60 - 140 cycles, but we use something lower here)
+      case Instruction::FAdd:
+      case Instruction::FSub:
+      case Instruction::FMul:
+      case Instruction::FDiv:
+      case Instruction::FRem:
+        return 5;
+      default:
+        printf("In getArithmeticInstrCost2: unknown %d\n", Opcode);
+        break;
+    }
+    return BaseT::getArithmeticInstrCost(Opcode, Ty, CostKind, Op1Info, Op2Info,
+                                         Args, CxtI);
+  }
   // TODO: Handle scalar type.
   if (!LT.second.isVector())
     return BaseT::getArithmeticInstrCost(Opcode, Ty, CostKind, Op1Info, Op2Info,
diff --git a/llvm/lib/Transforms/InstCombine/InstCombineMulDivRem.cpp b/llvm/lib/Transforms/InstCombine/InstCombineMulDivRem.cpp
index f4f3644acfe5..7431c294411e 100644
--- a/llvm/lib/Transforms/InstCombine/InstCombineMulDivRem.cpp
+++ b/llvm/lib/Transforms/InstCombine/InstCombineMulDivRem.cpp
@@ -158,34 +158,6 @@ static Value *foldMulShl1(BinaryOperator &Mul, bool CommuteOperands,
     return Builder.CreateShl(X, Z, Mul.getName(), HasNUW, PropagateNSW);
   }
 
-  // Similar to above, but an increment of the shifted value becomes an add:
-  // X * ((1 << Z) + 1) --> (X * (1 << Z)) + X --> (X << Z) + X
-  // This increases uses of X, so it may require a freeze, but that is still
-  // expected to be an improvement because it removes the multiply.
-  BinaryOperator *Shift;
-  if (match(Y, m_OneUse(m_Add(m_BinOp(Shift), m_One()))) &&
-      match(Shift, m_OneUse(m_Shl(m_One(), m_Value(Z))))) {
-    bool PropagateNSW = HasNSW && Shift->hasNoSignedWrap();
-    Value *FrX = X;
-    if (!isGuaranteedNotToBeUndef(X))
-      FrX = Builder.CreateFreeze(X, X->getName() + ".fr");
-    Value *Shl = Builder.CreateShl(FrX, Z, "mulshl", HasNUW, PropagateNSW);
-    return Builder.CreateAdd(Shl, FrX, Mul.getName(), HasNUW, PropagateNSW);
-  }
-
-  // Similar to above, but a decrement of the shifted value is disguised as
-  // 'not' and becomes a sub:
-  // X * (~(-1 << Z)) --> X * ((1 << Z) - 1) --> (X << Z) - X
-  // This increases uses of X, so it may require a freeze, but that is still
-  // expected to be an improvement because it removes the multiply.
-  if (match(Y, m_OneUse(m_Not(m_OneUse(m_Shl(m_AllOnes(), m_Value(Z))))))) {
-    Value *FrX = X;
-    if (!isGuaranteedNotToBeUndef(X))
-      FrX = Builder.CreateFreeze(X, X->getName() + ".fr");
-    Value *Shl = Builder.CreateShl(FrX, Z, "mulshl");
-    return Builder.CreateSub(Shl, FrX, Mul.getName());
-  }
-
   return nullptr;
 }
 
@@ -428,56 +400,12 @@ Instruction *InstCombinerImpl::visitMul(BinaryOperator &I) {
     }
   }
 
-  // Fold the following two scenarios:
-  //   1) i1 mul -> i1 and.
-  //   2) X * Y --> X & Y, iff X, Y can be only {0,1}.
-  // Note: We could use known bits to generalize this and related patterns with
-  // shifts/truncs
-  if (Ty->isIntOrIntVectorTy(1) ||
-      (match(Op0, m_And(m_Value(), m_One())) &&
-       match(Op1, m_And(m_Value(), m_One()))))
-    return BinaryOperator::CreateAnd(Op0, Op1);
 
   if (Value *R = foldMulShl1(I, /* CommuteOperands */ false, Builder))
     return replaceInstUsesWith(I, R);
   if (Value *R = foldMulShl1(I, /* CommuteOperands */ true, Builder))
     return replaceInstUsesWith(I, R);
 
-  // (zext bool X) * (zext bool Y) --> zext (and X, Y)
-  // (sext bool X) * (sext bool Y) --> zext (and X, Y)
-  // Note: -1 * -1 == 1 * 1 == 1 (if the extends match, the result is the same)
-  if (((match(Op0, m_ZExt(m_Value(X))) && match(Op1, m_ZExt(m_Value(Y)))) ||
-       (match(Op0, m_SExt(m_Value(X))) && match(Op1, m_SExt(m_Value(Y))))) &&
-      X->getType()->isIntOrIntVectorTy(1) && X->getType() == Y->getType() &&
-      (Op0->hasOneUse() || Op1->hasOneUse() || X == Y)) {
-    Value *And = Builder.CreateAnd(X, Y, "mulbool");
-    return CastInst::Create(Instruction::ZExt, And, Ty);
-  }
-  // (sext bool X) * (zext bool Y) --> sext (and X, Y)
-  // (zext bool X) * (sext bool Y) --> sext (and X, Y)
-  // Note: -1 * 1 == 1 * -1  == -1
-  if (((match(Op0, m_SExt(m_Value(X))) && match(Op1, m_ZExt(m_Value(Y)))) ||
-       (match(Op0, m_ZExt(m_Value(X))) && match(Op1, m_SExt(m_Value(Y))))) &&
-      X->getType()->isIntOrIntVectorTy(1) && X->getType() == Y->getType() &&
-      (Op0->hasOneUse() || Op1->hasOneUse())) {
-    Value *And = Builder.CreateAnd(X, Y, "mulbool");
-    return CastInst::Create(Instruction::SExt, And, Ty);
-  }
-
-  // (zext bool X) * Y --> X ? Y : 0
-  // Y * (zext bool X) --> X ? Y : 0
-  if (match(Op0, m_ZExt(m_Value(X))) && X->getType()->isIntOrIntVectorTy(1))
-    return SelectInst::Create(X, Op1, ConstantInt::getNullValue(Ty));
-  if (match(Op1, m_ZExt(m_Value(X))) && X->getType()->isIntOrIntVectorTy(1))
-    return SelectInst::Create(X, Op0, ConstantInt::getNullValue(Ty));
-
-  // mul (sext X), Y -> select X, -Y, 0
-  // mul Y, (sext X) -> select X, -Y, 0
-  if (match(&I, m_c_Mul(m_OneUse(m_SExt(m_Value(X))), m_Value(Y))) &&
-      X->getType()->isIntOrIntVectorTy(1))
-    return SelectInst::Create(X, Builder.CreateNeg(Y, "", I.hasNoSignedWrap()),
-                              ConstantInt::getNullValue(Op0->getType()));
-
   Constant *ImmC;
   if (match(Op1, m_ImmConstant(ImmC))) {
     // (sext bool X) * C --> X ? -C : 0
@@ -486,30 +414,6 @@ Instruction *InstCombinerImpl::visitMul(BinaryOperator &I) {
       return SelectInst::Create(X, NegC, ConstantInt::getNullValue(Ty));
     }
 
-    // (ashr i32 X, 31) * C --> (X < 0) ? -C : 0
-    const APInt *C;
-    if (match(Op0, m_OneUse(m_AShr(m_Value(X), m_APInt(C)))) &&
-        *C == C->getBitWidth() - 1) {
-      Constant *NegC = ConstantExpr::getNeg(ImmC);
-      Value *IsNeg = Builder.CreateIsNeg(X, "isneg");
-      return SelectInst::Create(IsNeg, NegC, ConstantInt::getNullValue(Ty));
-    }
-  }
-
-  // (lshr X, 31) * Y --> (X < 0) ? Y : 0
-  // TODO: We are not checking one-use because the elimination of the multiply
-  //       is better for analysis?
-  const APInt *C;
-  if (match(&I, m_c_BinOp(m_LShr(m_Value(X), m_APInt(C)), m_Value(Y))) &&
-      *C == C->getBitWidth() - 1) {
-    Value *IsNeg = Builder.CreateIsNeg(X, "isneg");
-    return SelectInst::Create(IsNeg, Y, ConstantInt::getNullValue(Ty));
-  }
-
-  // (and X, 1) * Y --> (trunc X) ? Y : 0
-  if (match(&I, m_c_BinOp(m_OneUse(m_And(m_Value(X), m_One())), m_Value(Y)))) {
-    Value *Tr = Builder.CreateTrunc(X, CmpInst::makeCmpResultType(Ty));
-    return SelectInst::Create(Tr, Y, ConstantInt::getNullValue(Ty));
   }
 
   // ((ashr X, 31) | 1) * X --> abs(X)
@@ -2178,9 +2082,7 @@ Instruction *InstCombinerImpl::visitURem(BinaryOperator &I) {
   // X urem Y -> X and Y-1, where Y is a power of 2,
   Value *Op0 = I.getOperand(0), *Op1 = I.getOperand(1);
   Type *Ty = I.getType();
-  if (isKnownToBeAPowerOfTwo(Op1, /*OrZero*/ true, 0, &I)) {
-    // This may increase instruction count, we don't enforce that Y is a
-    // constant.
+  if (isa<Constant>(Op1) && isKnownToBeAPowerOfTwo(Op1, /*OrZero*/ true, 0, &I)) {
     Constant *N1 = Constant::getAllOnesValue(Ty);
     Value *Add = Builder.CreateAdd(Op1, N1);
     return BinaryOperator::CreateAnd(Op0, Add);
diff --git a/llvm/lib/Transforms/Scalar/SimplifyCFGPass.cpp b/llvm/lib/Transforms/Scalar/SimplifyCFGPass.cpp
index 11de37f7a7c1..3b55f7731dab 100644
--- a/llvm/lib/Transforms/Scalar/SimplifyCFGPass.cpp
+++ b/llvm/lib/Transforms/Scalar/SimplifyCFGPass.cpp
@@ -275,7 +275,12 @@ static bool simplifyFunctionCFGImpl(Function &F, const TargetTransformInfo &TTI,
   bool EverChanged = removeUnreachableBlocks(F, DT ? &DTU : nullptr);
   EverChanged |=
       tailMergeBlocksWithSimilarFunctionTerminators(F, DT ? &DTU : nullptr);
-  EverChanged |= iterativelySimplifyCFG(F, TTI, DT ? &DTU : nullptr, Options);
+  // turn off block speculation in SimplifyCFG by overriding
+  // the option locally.
+  SimplifyCFGOptions NoSpecOptions = Options;
+  NoSpecOptions.speculateBlocks(false).speculateUnpredictables(false);
+  EverChanged |=
+      iterativelySimplifyCFG(F, TTI, DT ? &DTU : nullptr, NoSpecOptions);
 
   // If neither pass changed anything, we're done.
   if (!EverChanged) return false;
diff --git a/llvm/lib/Transforms/Utils/SimplifyCFG.cpp b/llvm/lib/Transforms/Utils/SimplifyCFG.cpp
index f23e28888931..ad34c29537a5 100644
--- a/llvm/lib/Transforms/Utils/SimplifyCFG.cpp
+++ b/llvm/lib/Transforms/Utils/SimplifyCFG.cpp
@@ -386,10 +386,7 @@ static void AddPredecessorToBlock(BasicBlock *Succ, BasicBlock *NewPred,
 /// expensive.
 static InstructionCost computeSpeculationCost(const User *I,
                                               const TargetTransformInfo &TTI) {
-  assert((!isa<Instruction>(I) ||
-          isSafeToSpeculativelyExecute(cast<Instruction>(I))) &&
-         "Instruction is not safe to speculatively execute!");
-  return TTI.getInstructionCost(I, TargetTransformInfo::TCK_SizeAndLatency);
+  return TTI::TCC_Expensive;
 }
 
 /// If we have a merge point of an "if condition" as accepted above,
@@ -2999,6 +2996,8 @@ static bool validateAndCostRequiredSelects(BasicBlock *BB, BasicBlock *ThenBB,
 /// \returns true if the conditional block is removed.
 bool SimplifyCFGOpt::SpeculativelyExecuteBB(BranchInst *BI,
                                             BasicBlock *ThenBB) {
+  // disable speculative if-conversion, i.e. we won't execute both branches of a conditional branch
+  return false;
   if (!Options.SpeculateBlocks)
     return false;
 
@@ -3478,6 +3477,8 @@ static bool FoldCondBranchOnValueKnownInPredecessor(BranchInst *BI,
 static bool FoldTwoEntryPHINode(PHINode *PN, const TargetTransformInfo &TTI,
                                 DomTreeUpdater *DTU, const DataLayout &DL,
                                 bool SpeculateUnpredictables) {
+  // disable folding to avoid predicated selects.
+  return false;
   // Ok, this is a two entry PHI node.  Check to see if this is a simple "if
   // statement", which has a very simple dominance structure.  Basically, we
   // are trying to find the condition that is being branched on, which
@@ -6167,6 +6168,8 @@ static void removeSwitchAfterSelectFold(SwitchInst *SI, PHINode *PHI,
 static bool trySwitchToSelect(SwitchInst *SI, IRBuilder<> &Builder,
                               DomTreeUpdater *DTU, const DataLayout &DL,
                               const TargetTransformInfo &TTI) {
+  // disable switch->select lowering to keep cheap branches.
+  return false;
   Value *const Cond = SI->getCondition();
   PHINode *PHI = nullptr;
   BasicBlock *CommonDest = nullptr;
@@ -6643,6 +6646,8 @@ static void reuseTableCompare(
 static bool SwitchToLookupTable(SwitchInst *SI, IRBuilder<> &Builder,
                                 DomTreeUpdater *DTU, const DataLayout &DL,
                                 const TargetTransformInfo &TTI) {
+  // disable switch->lookup-table lowering to avoid table eval.
+  return false;
   assert(SI->getNumCases() > 1 && "Degenerate switch?");
 
   BasicBlock *BB = SI->getParent();
